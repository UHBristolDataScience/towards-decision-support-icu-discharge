{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to clean the data extracted from MIMIC, and save clean version for future use.\n",
    "\n",
    "- Remove clearly anomalous values.\n",
    "- Sum GCS components, remove individual components, and introduce GCS_total.\n",
    "- Convert units for consisitency with GICU (UK data).\n",
    "- Introduce 'airway' variable (remove PEEP and AIRWAY)...this is a reduced version of current AIRWAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import graphlab.aggregate as agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: in the following mapping we exclude venous po2 and pco2, and diastolic bp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_mapping = dict()\n",
    "variable_mapping['fio2'] = [226754, 227009, 227010,223835]\n",
    "variable_mapping['resp'] = [220210, 224688, 224689, 224690]\n",
    "variable_mapping['po2'] = [226770,227039,220224] \n",
    "variable_mapping['pco2'] = [220235,227036]  \n",
    "variable_mapping['temp'] = [223761, 223762, 224027] \n",
    "variable_mapping['hr'] = [220045]\n",
    "variable_mapping['bp'] = [220050, 220059, 220179, 224167, 225309, 227243, 226850, 226852]\n",
    "variable_mapping['k'] = [220640, 227464, 227442, 226772, 226535]\n",
    "variable_mapping['na'] = [220645, 226534, 226776]\n",
    "variable_mapping['hco3'] = [224826, 226759, 227443]\n",
    "variable_mapping['spo2'] = [220227, 220277, 226860,226861,226862,226863,226865,228232]\n",
    "variable_mapping['bun'] = [225624, 227000, 227001]\n",
    "variable_mapping['airway'] = [223838, 224832, 224391, 227810,223837, 224829]\n",
    "variable_mapping['gcs'] = [220739, 223900, 223901, 226755, 226756, 226757, 226758, 227011, 227012, 227013, 227014,228112]\n",
    "variable_mapping['creatinine'] = [220615, 226752, 227005]\n",
    "variable_mapping['pain'] = [223791, 227881]\n",
    "variable_mapping['urine'] = [227519, 227059]\n",
    "variable_mapping['haemoglobin'] = [220228]\n",
    "variable_mapping['peep'] = [220339, 224699, 224700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following dictionary of tuples to check for non-physical variable values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "physical_limit = dict()\n",
    "physical_limit['creatinine'] = (0.0, 50.0)\n",
    "physical_limit['fio2'] = (0.0, 100.0)     \n",
    "physical_limit['resp'] = (0.0,100.0)      \n",
    "physical_limit['po2'] = (0.0,500.0)\n",
    "physical_limit['pco2'] = (0.0,500.0) \n",
    "physical_limit['temp'] = (80.0, 120.0)    \n",
    "physical_limit['hr'] = (0.0, 250.0)  \n",
    "physical_limit['bp'] = (0.0, 500.0) \n",
    "physical_limit['k'] = (0.0, 50.0)   \n",
    "physical_limit['na'] = (0.0, 500.0)  \n",
    "physical_limit['hco3'] = (0,100.0)    \n",
    "physical_limit['spo2'] = (10.0, 100.0) \n",
    "physical_limit['bun'] = (0.0,300.0)  \n",
    "physical_limit['gcs'] = (0.0, 16.0)  \n",
    "physical_limit['pain'] = (0.0, 10.0) \n",
    "physical_limit['peep'] = (0.0, 50.0)          \n",
    "physical_limit['haemoglobin'] = (0.0, 100.0)  \n",
    "physical_limit['airway'] = (None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _remove_anomalies(data, physical_limit, variable_dict, verbose=False):\n",
    "    \n",
    "    ## define which ITEMIDs correspond to which variables.  \n",
    "    get_var = lambda it: [variable for variable,items in variable_dict.iteritems() if it in items][0]\n",
    "    all_itemids = [item for sublist in variable_dict.values() for item in sublist]\n",
    "    var_id = {item: get_var(item) for item in all_itemids}\n",
    "    \n",
    "    data['remove_col'] = data.apply(lambda row: 1 if row['C.VALUENUM']>physical_limit[var_id[row['C.ITEMID']]][1] or row['C.VALUENUM']<physical_limit[var_id[row['C.ITEMID']]][0] else 0)\n",
    "    \n",
    "    ## now filter the data frame:\n",
    "    print \"%d rows to remove:\" %sum(data['remove_col']==1)\n",
    "    \n",
    "    if verbose:\n",
    "        print \"For example:\"\n",
    "        removed = data[data['remove_col']==1].sample(0.001)\n",
    "        removed.print_rows(num_rows=20)\n",
    "    \n",
    "    data = data[data['remove_col']==0]\n",
    "    data = data.remove_column('remove_col')\n",
    "    print \"Anomalies removed.\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and remove anomalies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to cm1788@bristol.ac.uk and will expire on October 04, 2019.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1553265369.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250927 rows to remove:\n",
      "Anomalies removed.\n"
     ]
    }
   ],
   "source": [
    "all_data = graphlab.SFrame('mimic_all_data/')\n",
    "all_data = all_data.filter_by(column_name='C.ITEMID', values=[226062,226063,227516,228151], exclude=True)\n",
    "all_data = _remove_anomalies(all_data, physical_limit, variable_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add column to data that says what type of variable it is (i.e. the variable name):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_var = lambda it: [variable for variable,items in variable_mapping.iteritems() if it in items][0]\n",
    "all_data['VARIABLE'] = all_data['C.ITEMID'].apply(lambda itemid: get_var(itemid))\n",
    "all_data.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now sum GCS components:  \n",
    "(And remove those that do not have all 3 cpts measured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gcs_summed = all_data.filter_by(\n",
    "                        column_name='C.ITEMID', \n",
    "                        values=variable_mapping['gcs']\n",
    "                                ).groupby(\n",
    "                                        key_columns=['C.ICUSTAY_ID', 'C.CHARTTIME'], \n",
    "                                        operations={'C.VALUENUM':agg.SUM('C.VALUENUM'), \n",
    "                                                     'ncpts':agg.COUNT('C.VALUENUM'),\n",
    "                                                     'hrs_bd':agg.SELECT_ONE('hrs_bd'),\n",
    "                                                     'C.HADM_ID':agg.SELECT_ONE('C.HADM_ID'),\n",
    "                                                     'C.SUBJECT_ID':agg.SELECT_ONE('C.SUBJECT_ID'),\n",
    "                                                     'C.ITEMID':agg.MIN('C.ITEMID'),\n",
    "                                                     'C.VALUE':agg.SELECT_ONE('C.VALUE',),\n",
    "                                                     'C.VALUEUOM':agg.SELECT_ONE('C.VALUEUOM'),\n",
    "                                                     'D.LABEL':agg.SELECT_ONE('D.LABEL'),\n",
    "                                                     'D.UNITNAME':agg.SELECT_ONE('D.UNITNAME'),\n",
    "                                                     'II.INTIME':agg.SELECT_ONE('II.INTIME'),\n",
    "                                                     'II.LOS':agg.SELECT_ONE('II.LOS'),\n",
    "                                                     'II.OUTTIME':agg.SELECT_ONE('II.OUTTIME'),\n",
    "                                                     'final_4hr':agg.SELECT_ONE('final_4hr'),\n",
    "                                                     'final_24hr':agg.SELECT_ONE('final_24hr'),\n",
    "                                                     'cohort':agg.SELECT_ONE('cohort'),\n",
    "                                                     'in_h_death':agg.SELECT_ONE('in_h_death'),\n",
    "                                                     'in_icu_death':agg.SELECT_ONE('in_icu_death'),\n",
    "                                                     'readmit':agg.SELECT_ONE('readmit'),\n",
    "                                                     'outcome':agg.SELECT_ONE('outcome'),\n",
    "                                                     'VARIABLE':agg.SELECT_ONE('VARIABLE')\n",
    "                                                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 1% of GCS measures are not 'full' (i.e. one or more cpt missing)\n",
    "We - remove these because it would be unfair to test on two components without altering the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0127 of gcs measures not complete.\n"
     ]
    }
   ],
   "source": [
    "_frac_incomplete = sum(gcs_summed['ncpts']<3)/float(len(gcs_summed))\n",
    "print \"%.4f of gcs measures not complete.\" %_frac_incomplete\n",
    "gcs_summed = gcs_summed[gcs_summed['ncpts']==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all single GCS components and append the complete GCS values to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = all_data.filter_by(column_name='C.ITEMID', values=variable_mapping['gcs'], exclude=True)\n",
    "gcs_summed = gcs_summed.remove_column('ncpts')\n",
    "all_data = all_data.append(gcs_summed)\n",
    "## VARIABLE='GCS' is now GCS total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And convert all required units to be consistent with our UK data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_to_convert = ['creatinine', 'temp', 'po2', 'pco2', 'bun']\n",
    "\n",
    "conv_crea = lambda crea: 88.42 * crea  ## convert from mg/dL (MIMIC) to umol/L (GICU)\n",
    "conv_temp = lambda temp: (temp-32)/1.8 ## convert from Farenhiet (MIMIC) to Celcius (GICU)\n",
    "conv_bg = lambda gas: 0.1333 * gas   ## convert blod gas from mmHg (MIMIC) to kPa (GICU)\n",
    "conv_bun = lambda bun: 0.3571 * bun  ## convert mg/dL (MIMC) to mmol/L (GICU)\n",
    "\n",
    "def _convert(var, val):\n",
    "    \n",
    "    new_val = None\n",
    "    if var=='creatinine':\n",
    "        new_val = conv_crea(val)\n",
    "    elif var=='temp':\n",
    "        if val==None:\n",
    "            new_val=None\n",
    "        else:\n",
    "            new_val = conv_temp(val)\n",
    "    elif var=='po2' or var=='pco2':\n",
    "        new_val = conv_bg(val)\n",
    "    elif var=='bun':\n",
    "        new_val = conv_bun(val)\n",
    "        \n",
    "    return new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['C.VALUENUM'] = all_data.apply(lambda row: _convert(row['VARIABLE'], row['C.VALUENUM']) if (row['VARIABLE'] in units_to_convert and row['C.VALUENUM']!=None) else row['C.VALUENUM']) \n",
    "all_data.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now work out if airway is patent...\n",
    "\n",
    "- We simply use presence of ETT as proxy for non-patent airway. \n",
    "- remove PEEP (it would be possible to stipulate PEEP + ETT -> non-patent, but simultaneity calculation is an unecessary complication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "airway_reduced = all_data.filter_by(\n",
    "                            column_name='C.ITEMID', \n",
    "                            values=variable_mapping['airway']\n",
    "                            ).groupby(key_columns=['C.ICUSTAY_ID', 'C.CHARTTIME'], \n",
    "                                      operations={'hrs_bd':agg.SELECT_ONE('hrs_bd'),\n",
    "                                                 'C.HADM_ID':agg.SELECT_ONE('C.HADM_ID'),\n",
    "                                                 'C.SUBJECT_ID':agg.SELECT_ONE('C.SUBJECT_ID'),\n",
    "                                                 'C.ITEMID':agg.MIN('C.ITEMID'),\n",
    "                                                 'C.VALUE':agg.SELECT_ONE('C.VALUE',),\n",
    "                                                 'C.VALUEUOM':agg.SELECT_ONE('C.VALUEUOM'),\n",
    "                                                 'D.LABEL':agg.SELECT_ONE('D.LABEL'),\n",
    "                                                 'D.UNITNAME':agg.SELECT_ONE('D.UNITNAME'),\n",
    "                                                 'II.INTIME':agg.SELECT_ONE('II.INTIME'),\n",
    "                                                 'II.LOS':agg.SELECT_ONE('II.LOS'),\n",
    "                                                 'II.OUTTIME':agg.SELECT_ONE('II.OUTTIME'),\n",
    "                                                 'final_4hr':agg.SELECT_ONE('final_4hr'),\n",
    "                                                 'final_24hr':agg.SELECT_ONE('final_24hr'),\n",
    "                                                 'cohort':agg.SELECT_ONE('cohort'),\n",
    "                                                 'in_h_death':agg.SELECT_ONE('in_h_death'),\n",
    "                                                 'in_icu_death':agg.SELECT_ONE('in_icu_death'),\n",
    "                                                 'readmit':agg.SELECT_ONE('readmit'),\n",
    "                                                 'outcome':agg.SELECT_ONE('outcome'),\n",
    "                                                 'VARIABLE':agg.SELECT_ONE('VARIABLE')\n",
    "                                                })\n",
    "\n",
    "airway_reduced['C.VALUENUM'] = airway_reduced['C.ICUSTAY_ID'].apply(lambda x: 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all PEEP and AIRWAY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = all_data.filter_by(column_name='C.ITEMID', values=variable_mapping['peep'], exclude=True)\n",
    "all_data = all_data.filter_by(column_name='C.ITEMID', values=variable_mapping['airway'], exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airway_reduced['C.VALUENUM'] = airway_reduced['C.VALUENUM'].apply(lambda x: 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add reduced airway variable back in and save this 'clean' version of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = all_data.append(airway_reduced)\n",
    "all_data.save('mimic_all_data_CLEANED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now extract the CALLOUT times (RFD flags) for each icustay and add these to the data: \n",
    "\n",
    "For each ICUSTAY want to get the corresponding successful CALLOUTs (only those with outcomes marked as 'Discharged'). There are a small number of stays with mutliple succesful discharges, we remove these instances from the data to avoid confusion (they correspond the patients being transfered between different ICUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Reloading: all_data = graphlab.SFrame('mimic_all_data_CLEANED/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql mysql://root:mysql2016@localhost/MIMIC?unix_socket=/run/mysqld/mysqld.sock\n",
    "%sql USE MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34499 rows affected.\n",
      "There are 208 stays with more than one successful CALLOUT (i.e. transfers).\n"
     ]
    }
   ],
   "source": [
    "callouts = %sql SELECT * FROM CALLOUT\n",
    "callouts = graphlab.SFrame(callouts.DataFrame())\n",
    "_stays = all_data.groupby(key_columns='C.ICUSTAY_ID', operations={'HADM_ID':agg.SELECT_ONE('C.HADM_ID'), 'IN':agg.SELECT_ONE('II.INTIME'), 'OUT':agg.SELECT_ONE('II.OUTTIME')})\n",
    "_stays_join = _stays.join(callouts, how='inner', on='HADM_ID')\n",
    "_stays_join['RFD'] = _stays_join['CREATETIME'].apply(lambda ti: ti.replace(tzinfo=None))\n",
    "_stays_join['callout_match'] = _stays_join.apply(lambda row: 1 if (row['RFD']>=row['IN'] and row['RFD']<=row['OUT']) else 0)\n",
    "counts = _stays_join[(_stays_join['callout_match']==1) * (_stays_join['CALLOUT_OUTCOME']=='Discharged')].groupby(key_columns='C.ICUSTAY_ID', operations={'count':agg.COUNT('RFD')})\n",
    "print \"There are %d stays with more than one successful CALLOUT (i.e. transfers).\" %sum(counts['count']>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove these stays: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_stays = counts[counts['count']>1]['C.ICUSTAY_ID']\n",
    "_stays_join = _stays_join[(_stays_join['callout_match']==1) * (_stays_join['CALLOUT_OUTCOME']=='Discharged')]\n",
    "_stays_join = _stays_join.filter_by(column_name='C.ICUSTAY_ID', values=remove_stays, exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the original 14430 icu stays,\n",
      "11286 remain (have successful single callouts)\n"
     ]
    }
   ],
   "source": [
    "print \"Of the original %d icu stays,\" %len(all_data['C.ICUSTAY_ID'].unique())\n",
    "print \"%d remain (have successful single callouts)\" %len(_stays_join['C.ICUSTAY_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: successful discharge here is different to \"positive outcome\" follwoing discharge. Successful simply means the patient did actually leave the icu (i.e. the callout was acted upon) \n",
    "\n",
    "#### We now join the CALLOUTS (RFD flags) to the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_stays_join = _stays_join['C.ICUSTAY_ID', 'RFD']\n",
    "all_data = all_data.join(_stays_join, how='inner', on='C.ICUSTAY_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now add a column 'hrs_bRFD':\n",
    "\n",
    "This is similar to the column 'hrs_bd' which we added previoulsy. We will filter on this column later to construct the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['hrs_bRFD'] = all_data.apply(lambda row: (row['RFD'] - row['C.CHARTTIME']).total_seconds() / float(60**2))\n",
    "all_data.save('mimic_all_data_CLEANED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 5495513 rows in the cleaned data.\n"
     ]
    }
   ],
   "source": [
    "print \"There are a total of %d rows in the cleaned data.\" %len(all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
